{"cells":[{"cell_type":"markdown","metadata":{"id":"K2CYQhbxW9nP"},"source":["### Μέλη Ομάδας:\n","Ον/μο1:  Ναταλία-Μαρία Γρηγοριάδου\n","Αρ. Μητρώου 1:  03118940\n","\n","Ον/μο2:  Νικόλαος Τασόπουλος\n","Αρ. Μητρώου 2:  03118858"]},{"cell_type":"markdown","metadata":{"id":"heT7siZWZjQD"},"source":["# Τεχνητή Νοημοσύνη: Εργαστηριακή Άσκηση 3 \n","Στην άσκηση αυτή θα υλοποιηθούν διάφοροι (σχετικά απλοί) αλγόριθμοι μηχανικής μάθησης για την αυτόματη αναγνώριση μεταξύ 3 μουσικών είδών απο τα δεδομένα που προσφέρει η υπηρεσία Spotify. Συγκεκριμένα, θα δίνονται δύο σύνολα δεδομένων $$Ζ_{train}=\\{(x_1,y_1),\\dots,(x_n,y_n)\\}$$ $$Z_{test} = \\{(x_j,y_j),\\dots{,(x_k,y_k)}\\}$$ όπου κάθε $x_i\\in{\\mathbb{R}^p}$ είναι ένα διάνυσμα με τα μουσικά χαρακτηριστικά κάθε κομματιού (όπως dancability, acousticness κ.α.) και $y_i$ είναι το είδος του κομματιού - ένας ακέραιος στο $[0,2]$. Σε κάθε περίπτωση καλείστε να σχεδιάσετε έναν ταξινομητή, δηλαδή μια απεικόνιση $$f:\\mathbb{R}^p\\rightarrow{[0,2]}$$"]},{"cell_type":"markdown","metadata":{"id":"Rvm0mywsZmit"},"source":["# 1ο Μέρος: Αξιολόγηση\n","Στο πρώτο μέρος της άσκησης θα υλοποιηθούν συναρτήσεις που θα χρησιμοποιηθούν για την αξιολόγηση των ταξινομητών που θα χρησιμοποιηθούν στα επόμενα μέρη.\n","\n","Παρακάτω σας δίνεται η κλάση Evaluate, η οποία υπολογίζει διάφορες μετρικές με τη μέθοδο get_metrics, εντοπίζει αντικείμενα που ταξινομήθηκαν λάθος και τα εμφανίζει (μέθοδος get_sample_of_wrong), και υπολογίζει τον πίνακα σύγχυσης (confusion matrix) όπου οπτικοποιούνται ανά κατηγορία οι προβλέψεις του ταξινομητή.\n","\n","Για το μέρος αυτό καλείστε να υλοποιήσετε στη μέθοδο my_accuracy τη μετρική accuracy, η οποία ορίζεται ως:\n","$$accuracy = \\frac{\\#σωστών\\_προβλέψεων}{\\#δεδομένων}$$\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"WlTj48uFZhyJ"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import random\n","\n","class Evaluate:\n","    def __init__(self, y_true, y_pred):\n","        self.y_true = y_true\n","        self.y_pred = y_pred\n","\n","    def my_accuracy(self):\n","      y_true = self.y_true\n","      y_pred = self.y_pred\n","      \n","      ##################\n","      ## Your code below\n","      \n","      acc=0\n","\n","      for y_t, y_p in zip(y_true, y_pred):\n","          if(y_t==y_p):\n","              acc+=1/len(y_true)\n","      \n","      ## Your code above\n","      ##################\n","      return acc\n","\n","    def get_metrics(self):\n","        precision = precision_score(self.y_true, self.y_pred, average = \"macro\")\n","        recall = recall_score(self.y_true, self.y_pred, average = \"macro\")\n","        f1 = f1_score(self.y_true, self.y_pred, average = \"macro\")\n","        results = {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": self.my_accuracy()}\n","        return results   \n","    \n","    def confusion_matrix(self):\n","        cm = confusion_matrix(self.y_true, self.y_pred)\n","        return cm \n","\n","    def get_evaluation_report(self):\n","        metrics = self.get_metrics()\n","        for m in metrics:\n","            print(m + ': ' + str(metrics[m]))\n","        cm = self.confusion_matrix()\n","        print(\"Confusion matrix: \")\n","        print(cm)"]},{"cell_type":"markdown","metadata":{"id":"3qcSvLy6ZpzB"},"source":["Παράδειγμα χρήσης της κλάσης. Κανονικά στο x θα υπάρχουν τα δεδομένα από το dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"S5hRZ9L1ZoNJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.75\n","recall: 0.75\n","f1: 0.75\n","accuracy: 0.75\n","Confusion matrix: \n","[[3 1]\n"," [1 3]]\n"]}],"source":["y_true = [1, 0, 1, 0, 0, 1, 1, 0]\n","y_pred = [1, 0, 1, 0, 1, 1, 0, 0]\n","\n","eval = Evaluate(y_true, y_pred)\n","eval = eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"h9Sex6aEZtt9"},"source":["# Dataset\n","\n","To dataset που σας δίνεται περιέχει πληθώρα μουσικών κομματιών για τα οποία έχουν καταγραφεί διάφορα χαρακτηριστικά τους, όπως επίσης και το μουσικό είδος στο οποίο ανήκουν. Στη συγκεκριμένη άσκηση θα δουλέψουμε με ένα υποσύνολο (αριθμητικών) χαρακτηριστικών, τα οποία συνεισφέρουν στον καθορισμό της μουσικής κατηγορίας κάθε κομματιού.  \n","\n","Τα χαρακτηριστικά τα οποία θα μελετήσουμε στην παρούσα άσκηση είναι τα \"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"speechiness\", ενώ οι κατηγορίες στις οποίες καλούμαστε να ταξινομήσουμε τα μουσικά κομμάτια είναι οι \"Electronic\", \"Rock\", και \"Rap\".  \n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RCVa4LWpqraw"},"outputs":[],"source":["# Σύνδεση του Google Colab με το Google Drive\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","path=\"D:/Users/Nikos/Projects/AI/lab3/\"\n","# path = \"~/projects/AI/lab3/\""]},{"cell_type":"markdown","metadata":{"id":"5sKETzTHNgyk"},"source":["Θα χρησιμοποιήσουμε τα DataFrames της βιβλιοθήκης pandas για να χειριστούμε τα δεδομένα μας. Μπορείτε να βρείτε περισσότερες πληροφορίες για τα pandas DataFrames στο αντίστοιχο [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"YvbVV9isZrwZ"},"outputs":[],"source":["import pandas as pd\n","from tqdm.notebook import tqdm "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YKpUJSpWqy-I"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instance_id</th>\n","      <th>artist_name</th>\n","      <th>track_name</th>\n","      <th>popularity</th>\n","      <th>acousticness</th>\n","      <th>danceability</th>\n","      <th>duration_ms</th>\n","      <th>energy</th>\n","      <th>instrumentalness</th>\n","      <th>key</th>\n","      <th>liveness</th>\n","      <th>loudness</th>\n","      <th>mode</th>\n","      <th>speechiness</th>\n","      <th>tempo</th>\n","      <th>obtained_date</th>\n","      <th>valence</th>\n","      <th>music_genre</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>32894.0</td>\n","      <td>Röyksopp</td>\n","      <td>Röyksopp's Night Out</td>\n","      <td>27.0</td>\n","      <td>0.00468</td>\n","      <td>0.652</td>\n","      <td>-1.0</td>\n","      <td>0.941</td>\n","      <td>0.79200</td>\n","      <td>A#</td>\n","      <td>0.115</td>\n","      <td>-5.201</td>\n","      <td>Minor</td>\n","      <td>0.0748</td>\n","      <td>100.889</td>\n","      <td>4-Apr</td>\n","      <td>0.759</td>\n","      <td>Electronic</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>46652.0</td>\n","      <td>Thievery Corporation</td>\n","      <td>The Shining Path</td>\n","      <td>31.0</td>\n","      <td>0.01270</td>\n","      <td>0.622</td>\n","      <td>218293.0</td>\n","      <td>0.890</td>\n","      <td>0.95000</td>\n","      <td>D</td>\n","      <td>0.124</td>\n","      <td>-7.043</td>\n","      <td>Minor</td>\n","      <td>0.0300</td>\n","      <td>115.002</td>\n","      <td>4-Apr</td>\n","      <td>0.531</td>\n","      <td>Electronic</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30097.0</td>\n","      <td>Dillon Francis</td>\n","      <td>Hurricane</td>\n","      <td>28.0</td>\n","      <td>0.00306</td>\n","      <td>0.620</td>\n","      <td>215613.0</td>\n","      <td>0.755</td>\n","      <td>0.01180</td>\n","      <td>G#</td>\n","      <td>0.534</td>\n","      <td>-4.617</td>\n","      <td>Major</td>\n","      <td>0.0345</td>\n","      <td>127.994</td>\n","      <td>4-Apr</td>\n","      <td>0.333</td>\n","      <td>Electronic</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62177.0</td>\n","      <td>Dubloadz</td>\n","      <td>Nitro</td>\n","      <td>34.0</td>\n","      <td>0.02540</td>\n","      <td>0.774</td>\n","      <td>166875.0</td>\n","      <td>0.700</td>\n","      <td>0.00253</td>\n","      <td>C#</td>\n","      <td>0.157</td>\n","      <td>-4.498</td>\n","      <td>Major</td>\n","      <td>0.2390</td>\n","      <td>128.014</td>\n","      <td>4-Apr</td>\n","      <td>0.270</td>\n","      <td>Electronic</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24907.0</td>\n","      <td>What So Not</td>\n","      <td>Divide &amp; Conquer</td>\n","      <td>32.0</td>\n","      <td>0.00465</td>\n","      <td>0.638</td>\n","      <td>222369.0</td>\n","      <td>0.587</td>\n","      <td>0.90900</td>\n","      <td>F#</td>\n","      <td>0.157</td>\n","      <td>-6.266</td>\n","      <td>Major</td>\n","      <td>0.0413</td>\n","      <td>145.036</td>\n","      <td>4-Apr</td>\n","      <td>0.323</td>\n","      <td>Electronic</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   instance_id           artist_name            track_name  popularity  \\\n","0      32894.0              Röyksopp  Röyksopp's Night Out        27.0   \n","1      46652.0  Thievery Corporation      The Shining Path        31.0   \n","2      30097.0        Dillon Francis             Hurricane        28.0   \n","3      62177.0              Dubloadz                 Nitro        34.0   \n","4      24907.0           What So Not      Divide & Conquer        32.0   \n","\n","   acousticness  danceability  duration_ms  energy  instrumentalness key  \\\n","0       0.00468         0.652         -1.0   0.941           0.79200  A#   \n","1       0.01270         0.622     218293.0   0.890           0.95000   D   \n","2       0.00306         0.620     215613.0   0.755           0.01180  G#   \n","3       0.02540         0.774     166875.0   0.700           0.00253  C#   \n","4       0.00465         0.638     222369.0   0.587           0.90900  F#   \n","\n","   liveness  loudness   mode  speechiness    tempo obtained_date  valence  \\\n","0     0.115    -5.201  Minor       0.0748  100.889         4-Apr    0.759   \n","1     0.124    -7.043  Minor       0.0300  115.002         4-Apr    0.531   \n","2     0.534    -4.617  Major       0.0345  127.994         4-Apr    0.333   \n","3     0.157    -4.498  Major       0.2390  128.014         4-Apr    0.270   \n","4     0.157    -6.266  Major       0.0413  145.036         4-Apr    0.323   \n","\n","  music_genre  \n","0  Electronic  \n","1  Electronic  \n","2  Electronic  \n","3  Electronic  \n","4  Electronic  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# read data in the form of pandas DataFrame\n","data = pd.read_csv(path + \"music_df_processed.csv\")\n","\n","# print the first 5 values of the DataFrame using .head() command\n","data.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"1mjeVnUCPVkR"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instance_id</th>\n","      <th>popularity</th>\n","      <th>acousticness</th>\n","      <th>danceability</th>\n","      <th>duration_ms</th>\n","      <th>energy</th>\n","      <th>instrumentalness</th>\n","      <th>liveness</th>\n","      <th>loudness</th>\n","      <th>speechiness</th>\n","      <th>tempo</th>\n","      <th>valence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>1.353100e+04</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","      <td>13531.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>55885.281502</td>\n","      <td>52.854482</td>\n","      <td>0.161863</td>\n","      <td>0.618556</td>\n","      <td>2.176361e+05</td>\n","      <td>0.691926</td>\n","      <td>0.137073</td>\n","      <td>0.197629</td>\n","      <td>-6.990060</td>\n","      <td>0.112838</td>\n","      <td>123.052186</td>\n","      <td>0.456102</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>20714.333985</td>\n","      <td>13.337100</td>\n","      <td>0.218414</td>\n","      <td>0.154893</td>\n","      <td>1.169185e+05</td>\n","      <td>0.186321</td>\n","      <td>0.277412</td>\n","      <td>0.159705</td>\n","      <td>3.190236</td>\n","      <td>0.112915</td>\n","      <td>28.347021</td>\n","      <td>0.235353</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>20005.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000001</td>\n","      <td>0.064500</td>\n","      <td>-1.000000e+00</td>\n","      <td>0.002590</td>\n","      <td>0.000000</td>\n","      <td>0.017300</td>\n","      <td>-37.124000</td>\n","      <td>0.022400</td>\n","      <td>35.551000</td>\n","      <td>0.020500</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>37978.500000</td>\n","      <td>44.000000</td>\n","      <td>0.008925</td>\n","      <td>0.516000</td>\n","      <td>1.819605e+05</td>\n","      <td>0.561000</td>\n","      <td>0.000000</td>\n","      <td>0.097600</td>\n","      <td>-8.664000</td>\n","      <td>0.038200</td>\n","      <td>99.998000</td>\n","      <td>0.271000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>55730.000000</td>\n","      <td>55.000000</td>\n","      <td>0.059300</td>\n","      <td>0.625000</td>\n","      <td>2.201990e+05</td>\n","      <td>0.708000</td>\n","      <td>0.000083</td>\n","      <td>0.130000</td>\n","      <td>-6.426000</td>\n","      <td>0.059800</td>\n","      <td>123.475000</td>\n","      <td>0.443000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>73834.000000</td>\n","      <td>62.000000</td>\n","      <td>0.233000</td>\n","      <td>0.731000</td>\n","      <td>2.634285e+05</td>\n","      <td>0.844000</td>\n","      <td>0.061350</td>\n","      <td>0.257000</td>\n","      <td>-4.791500</td>\n","      <td>0.148000</td>\n","      <td>142.636000</td>\n","      <td>0.630500</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>91759.000000</td>\n","      <td>99.000000</td>\n","      <td>0.994000</td>\n","      <td>0.977000</td>\n","      <td>4.497994e+06</td>\n","      <td>0.999000</td>\n","      <td>0.986000</td>\n","      <td>0.991000</td>\n","      <td>1.585000</td>\n","      <td>0.922000</td>\n","      <td>220.041000</td>\n","      <td>0.992000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        instance_id    popularity  acousticness  danceability   duration_ms  \\\n","count  13531.000000  13531.000000  13531.000000  13531.000000  1.353100e+04   \n","mean   55885.281502     52.854482      0.161863      0.618556  2.176361e+05   \n","std    20714.333985     13.337100      0.218414      0.154893  1.169185e+05   \n","min    20005.000000      0.000000      0.000001      0.064500 -1.000000e+00   \n","25%    37978.500000     44.000000      0.008925      0.516000  1.819605e+05   \n","50%    55730.000000     55.000000      0.059300      0.625000  2.201990e+05   \n","75%    73834.000000     62.000000      0.233000      0.731000  2.634285e+05   \n","max    91759.000000     99.000000      0.994000      0.977000  4.497994e+06   \n","\n","             energy  instrumentalness      liveness      loudness  \\\n","count  13531.000000      13531.000000  13531.000000  13531.000000   \n","mean       0.691926          0.137073      0.197629     -6.990060   \n","std        0.186321          0.277412      0.159705      3.190236   \n","min        0.002590          0.000000      0.017300    -37.124000   \n","25%        0.561000          0.000000      0.097600     -8.664000   \n","50%        0.708000          0.000083      0.130000     -6.426000   \n","75%        0.844000          0.061350      0.257000     -4.791500   \n","max        0.999000          0.986000      0.991000      1.585000   \n","\n","        speechiness         tempo       valence  \n","count  13531.000000  13531.000000  13531.000000  \n","mean       0.112838    123.052186      0.456102  \n","std        0.112915     28.347021      0.235353  \n","min        0.022400     35.551000      0.020500  \n","25%        0.038200     99.998000      0.271000  \n","50%        0.059800    123.475000      0.443000  \n","75%        0.148000    142.636000      0.630500  \n","max        0.922000    220.041000      0.992000  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# What can we see here?\n","data.describe()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Σχόλια:\n","* Από τον παραπάνω πίνακα μπορούμε να αντλήσουμε πληροφορίες για το εύρος των τιμών των χαρακτηριστικών (μέγιστες / ελάχιστες τιμές).\n","* Ακόμα, μπορούμε να πάρουμε στατιστικές πληροφορίες όπως τον μέσο όρο, και τα percentiles, δηλάδη τι μέγιστη τιμή έχουν υποσύνολα των δεδομένων μας.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0EtEH-M9Ikac"},"source":["## Επιλογή χαρακτηριστικών x και στόχων y.  \n","\n","Για λόγους απλότητας επιλέγουμε τα χαρακτηριστικά (inputs) και τις κατηγορίες-στόχους (genres). Καλείστε να διαχωρίσετε τα δεδομένα σε train/test set. Ας θεωρήσουμε το διαχωρισμό 30% - test set, 70% - train set."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import random"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"tHa_Qq0Efqxb"},"outputs":[],"source":["# χαρακτηριστικά\n","inputs = [\"acousticness\", \"danceability\", \"energy\", \"instrumentalness\", \"liveness\", \"speechiness\"]\n","\n","# κατηγορίες-στόχοι\n","output = \"music_genre\"\n","genres = [\"Electronic\", \"Rock\", \"Rap\"]\n","\n","# φιλτράρουμε το DataFrame ώστε να διατηρήσουμε μόνο τις 3 κατηγορίες που μας ενδιαφέρουν.\n","data = data[data[output].isin(genres)]\n","\n","# dictionary to map genre to label id \n","genres_to_id = {genre: i for i, genre in enumerate(genres)}\n","\n","# εδώ πρέπει να διαχωρίσετε τα δεδομένα σε train (70% των δεδομένων)/test set (30% των δεδομένων)\n","# ονομάστε τις μεταβλητές ως εξής:\n","# τα χαρακτηριστικά του train set: x_train\n","# τις κατηγορίες-στόχους του train set: y_train\n","# τα χαρακτηριστικά του test set: x_test\n","# τις κατηγορίες-στόχους του test set: y_test\n","x_test, y_test, x_train, y_train = [], [], [], []\n","##################\n","## Your code below\n","songGenreToNumber= {\"Electronic\":0, \"Rock\":1, \"Rap\":2}\n","listOfChar2Genre={}\n","count_elements_by_genre={}\n","\n","for row in data.itertuples(index=True, name='Pandas'):\n","    \n","    m = getattr(row,'music_genre')\n","    if m in count_elements_by_genre:\n","        \n","        count_elements_by_genre[m]+=1\n","    else:\n","        count_elements_by_genre[m]=1\n","\n","\n","\n","songs_already_visited={}\n","\n","alldata=0\n","seperator = 0.3\n","testCount_elements_by_genre={}\n","for songs in count_elements_by_genre.keys():\n","    alldata+=(count_elements_by_genre[songs])\n","    testCount_elements_by_genre[songs]=int(count_elements_by_genre[songs]*seperator)\n","\n","\n","    \n","\n","def addTestAndTrain (ok ,genre, characteristic, x_test, y_test, x_train, y_train):\n","    if(ok):\n","        y_test.append(genre)\n","        x_test.append(characteristic)\n","    else:\n","        x_train.append(characteristic)\n","        y_train.append(genre)\n","\n","# new code start\n","i=0\n","for row in data.itertuples(index=True, name='Pandas'):\n","    i+=i\n","    songGenre = getattr(row, 'music_genre') \n","\n","    addToTest = False\n","    \n","    if testCount_elements_by_genre[songGenre]>0:\n","        testCount_elements_by_genre[songGenre]-=1\n","        addToTest=True\n","    else:\n","        addToTest=False\n","    \n","    mylist=[]\n","    for characteristic in inputs:\n","            mylist.append(getattr(row,characteristic))\n","    addTestAndTrain(addToTest, songGenreToNumber[songGenre], mylist, x_test, y_test,x_train,y_train)\n","\n","\n","# ## Your code above\n","##################"]},{"cell_type":"markdown","metadata":{"id":"hhte3iixLg8C"},"source":["## Μορφή των δεδομένων  \n","\n","Βεβαιωθείτε ότι τα δεδομένα σας έχουν τη σωστή μορφή εκτυπώνοντας τον αριθμό γραμμών και στηλών για τα x_test, y_test, x_train, y_train."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FhDzmllUZvyp"},"outputs":[{"name":"stdout","output_type":"stream","text":["y_test size:  4058  y_train size:  9473\n","x_test size:  4058  x_train size:  9473\n","OK :)\n","you have added this more songs to train model:  4\n","[y_test] [5 songs showing] you should see OR 0 OR 1 OR 2 here:  [0, 0, 0, 0, 0]\n","[y_train] [5 songs showing] you should see OR 0 OR 1 OR 2 here:  [0, 0, 0, 0, 0]\n","[x_test] [2 songs showing] you should see 6 numbers(list) per song here: \n","[[0.00468, 0.652, 0.941, 0.792, 0.115, 0.0748], [0.0127, 0.622, 0.89, 0.95, 0.124, 0.03]]\n","[x_train] [2 songs showing] you should see 6 numbers(list) per song here: \n","[[0.0076799999999999, 0.556, 0.6809999999999999, 0.728, 0.0883, 0.0319], [0.000127, 0.442, 0.96, 0.8740000000000001, 0.1939999999999999, 0.0661]]\n"]}],"source":["# Shape of x_test, y_test, x_train, y_train\n","\n","##################\n","## Your code below\n","\n","\n","if((len(y_test) + len(y_train) == alldata) ):\n","    print(\"y_test size: \",len(y_test), \" y_train size: \",  len(y_train))\n","    print(\"x_test size: \",len(x_test), \" x_train size: \",  len(x_train))\n","    print(\"OK :)\")\n","    false = int(len(y_train)-len(y_test)*(7/3))\n","    if(false > 0):\n","        print(\"you have added this more songs to train model: \", false)\n","    print(\"[y_test] [5 songs showing] you should see OR 0 OR 1 OR 2 here: \",y_test[:5])\n","    print(\"[y_train] [5 songs showing] you should see OR 0 OR 1 OR 2 here: \",y_train[:5])\n","    print(\"[x_test] [2 songs showing] you should see 6 numbers(list) per song here: \")\n","    print(x_test[:2])\n","    print(\"[x_train] [2 songs showing] you should see 6 numbers(list) per song here: \")\n","    print(x_train[:2])\n","\n","else:\n","    print(\"NOT OK :( \")\n","    false = int(len(y_test)*(7/3)-len(y_train))\n","    print(false)\n","\n","## Your code above\n","##################"]},{"cell_type":"markdown","metadata":{"id":"QAQ3qN1NMVpf"},"source":["Αναφορικά με τις τιμές των χαρακτηριστικών, είναι σημαντικό να γνωρίζουμε το εύρος τους, δηλαδή τη μέγιστη και την ελάχιστη τιμή που λαμβάνει το κάθε χαρακτηριστικό. Εξερευνήστε το εύρος του κάθε χαρακτηριστικού στα train και test set. "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"twobPa_DMxI2"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'acousticness': 0.994, 'danceability': 0.975, 'energy': 0.999, 'instrumentalness': 0.98, 'liveness': 0.991, 'speechiness': 0.922}\n","{'acousticness': 1.39e-06, 'danceability': 0.104, 'energy': 0.00259, 'instrumentalness': 0.0, 'liveness': 0.0208, 'speechiness': 0.0226}\n"]}],"source":["# Range of x_train, x_test columns\n","\n","##################\n","## Your code below\n","maxValue ={\"acousticness\":-1, \"danceability\":-1, \"energy\":-1, \"instrumentalness\":-1, \"liveness\":-1, \"speechiness\":-1}\n","minValue = {\"acousticness\":10, \"danceability\":10, \"energy\":10, \"instrumentalness\":10, \"liveness\":10, \"speechiness\":10}\n","\n","\n","for acousticness, danceability, energy, instrumentalness, liveness, speechiness in x_train:\n","    \n","    maxValue[\"acousticness\"]=max(maxValue[\"acousticness\"], acousticness)  \n","    maxValue[\"danceability\"]=max(maxValue[\"danceability\"], danceability)\n","    maxValue[\"energy\"]=max(maxValue[\"energy\"], energy)\n","    maxValue[\"instrumentalness\"]=max(maxValue[\"instrumentalness\"], instrumentalness)\n","    maxValue[\"liveness\"]=max(maxValue[\"liveness\"], liveness)  \n","    maxValue[\"speechiness\"]=max(maxValue[\"speechiness\"], speechiness)\n","    minValue[\"acousticness\"]=min(minValue[\"acousticness\"], acousticness)  \n","    minValue[\"danceability\"]=min(minValue[\"danceability\"], danceability)\n","    minValue[\"energy\"]=min(minValue[\"energy\"], energy)\n","    minValue[\"instrumentalness\"]=min(minValue[\"instrumentalness\"], instrumentalness)\n","    minValue[\"liveness\"]=min(minValue[\"liveness\"], liveness)  \n","    minValue[\"speechiness\"]=min(minValue[\"speechiness\"], speechiness)\n","\n","\n","print(maxValue)\n","print(minValue)\n","## Your code above\n","##################"]},{"cell_type":"markdown","metadata":{"id":"jZH_VbsMM_TM"},"source":["Από την παραπάνω ανάλυση προκύπτουν κάποια ερωτήματα σημαντικά για τα επόμενα βήματα:\n","- Έχουν τα χαρακτηριστικά μας περίπου το ίδιο εύρος;\n","\n","- Σε πολλές εφαρμογές είναι σημαντικό τα χαρακτηριστικά να βρίσκονται στο εύρος [0, 1]. Ισχύει αυτό στην περίπτωσή μας; "]},{"cell_type":"markdown","metadata":{},"source":["# Απαντήσεις\n","* Από τις ελάχιστες και μέγιστες τιμές που τυπώνονται στο παραπάνω κομμάτι κώδικα παρατηρούμε ότι υπάρχουν κάποιες διαφορές στο εύρος των χαρακτηριστικών. Συγκεκριμένα, όσον αφορά την ελάχιστη τιμή τα acousticness, instrumentalness και energy έχουν σχεδόν μηδενική τιμή ενώ για την μέγιστη παρατηρούμε ότι τα acousticness, energy και liveness έχουν 0.99, τα instrumentalness και danceability 0.98 ενώ το speechiness έχει 0.92.\n","* Παρόλο που τα χαρακτηριστικά έχουν διαφορετικά εύρη, και οι τιμές και των έξι χαρακτηριστικών βρίσκονται στο εύρος [0,1] "]},{"cell_type":"markdown","metadata":{},"source":["# Τυχαιοποίηση δεδομένων\n","Στα y_test, x_test υπάρχει το 30% των δεδομένων που μας δίνεται στο αρχείο, με την σειρά που εμφανίζονται σε αυτό. Για να έχουμε πιο ολοκληρωμένη εικόνα για την επίδοση των ταξινομητών, εξετάζουμε τους ταξινομητές, στα παρακάτω μέρη ,με τυχαία 100 δείγματα του x_test (τα οποία βρίσκονται στα x_test2, y_test2). Έτσι κάθε φορά που τρέχουμε το παρακάτω κομμάτι του κώδικα, το σύνολο των δεδομένων ανανεώνεται και μας δίνει νέα αποτελέσματα επίδοσης. Φροντίζουμε, όμως, για την σύγκριση των ταξινομήτων να έχουν τρέξει με το ίδιο δείγμα δεδομένων.\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["y_test2, x_test2 =[],[]\n","\n","alreadyVisited={}\n","number_of_songs = 100\n","while(number_of_songs>0):\n","    randomNumber= random.randrange(0,(len(x_test)))\n","    newlist=[]\n","    newlist=list(x_test[randomNumber])\n","    newlist.append(randomNumber)\n","    if(str(newlist) in alreadyVisited):\n","        continue\n","    else:\n","        number_of_songs-=1\n","        x_test2.append(x_test[randomNumber])\n","        y_test2.append(y_test[randomNumber])"]},{"cell_type":"markdown","metadata":{"id":"bYMke4uRZ8Ae"},"source":["# 2o Μέρος: Υλοποίηση KNN\n","Στο δεύτερο μέρος της άσκησης θα υλοποιήσετε τον αλγόριθμο KNN για ταξινόμηση. Υπενθυμίζεται από τις διαφάνειες το πλάνο σχεδιασμού για τον ταξινομητή k κοντινότερων γειτόνων:\n","- Αποθηκεύουμε όλα τα δεδομένα ($Z_{train}$) στη μνήμη\n","  - Τα δεδομένα μπορούν αποθηκευτούν σε έναν πίνακα $n\\times{p}$ με χρήση του numpy\n","- Συγκρίνουμε την είσοδο με τα δεδομένα και βρίσκουμε τα k κοντινότερα ($k<n$) με βάση κάποια απόσταση.\n","  - Όταν μας δίνεται ένα \"φρέσκο\" δείγμα ως διάνυσμα από χαρακτηριστικά $x_i$ χρειαζόμαστε μια συνάρτηση που να υπολογίζει την απόσταση $d(x_i,x_j)$, όπου $x_j$ είναι το διάνυσμα που αντιστοιχεί στα χαρακτηριστικά ενός δείγματος από τα δεδομένα εκπαίδευσης. Θα πειραματιστείτε με την ευκλείδια απόσταση και την απόσταση συνημιτόνου. Στη συνέχεια ταξινομούνται τα δεδομένα εκπαίδευσης ως προς την απόστασή τους από το $x_i$ και επιλέγονται τα $k$ κοντινότερα\n","- Δίνουμε στην έξοδο την κλάση στην οποία ανήκει η πλειοψηφία των k κοντινότερων δεδομένων.\n","\n","Αφού κατασκευαστεί ο ταξινομητής θα αξιολογήσετε την επίδοσή του στα 100 πρώτα δείγματα του $Z_{test}$ για κάποιες τιμές του k που θα επιλέξετε εσείς, ξεκινώντας από $k=1$.\n","\n","Στην πράξη πολύ σπάνια θα χρειαστεί να υλοποιήσετε έναν αλγόριθμο μηχανικής μάθησης από το μηδέν, αφού υπάρχουν έτοιμες υλοποιήσεις, π.χ. σε πακέτα της python, οι οποίες είναι βελτιστοποιημένες και εύχρηστες. Το τελευταίο ζητούμενο  στο 2ο μέρος είναι να επαναλάβετε το παραπάνω πείραμα με την έτοιμη υλοποίηση του KNN που παρέχει η βιβλιοθήκη sklearn. Καλείστε να συγκρίνετε τα αποτελέσματα και τους χρόνους εκτέλεσης.\n","\n"," Σας δίνεται η κλάση KNN η οποία αρχικοποιείται με ένα σύνολο από δεδομένα x, ετικέτες y και το k για τον αλγόριθμο. Καλείστε να συμπληρώσετε τον κώδικα που λείπει στις μεθόδους distance, get_knn, και classify.\n","\n","Η απόσταση συνημιτόνου μεταξύ δύο διανυσμάτων u,v ορίζεται ως: $$d(u,v)= 1 - \\frac{u\\cdot{v}}{||u||_2||v||_2}$$"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import numpy as np\n","import statistics \n","from statistics import mode"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EMPfT1jTZ51F"},"outputs":[],"source":["from numpy import linalg\n","class KNN:\n","    def __init__(self, x, y, k, distance = \"euclidean\"):\n","        self.x = x\n","        self.y = y\n","        self.k = k\n","        self.distance = distance\n","        \n","    ## Compute the distance between the two vectors (2 rows of the DataFrame)\n","    # hint: use np.linalg.norm for eucledian\n","    # hint: use equation given above for cosine\n","    def get_distance(self, row1, row2):\n","      if self.distance=='euclidian':\n","        ##################\n","        ## Your code below\n","        dist = np.linalg.norm(np.array(row1)- np.array(row2))\n","        ## Your code above\n","        ##################\n","      elif self.distance=='cosine':\n","        ##################\n","        ## Your code below\n","        dist = 1 - np.inner(row1, row2) / (np.sqrt(np.dot(row1, row1)) * np.sqrt(np.dot(row2, row2)))\n","        ## Your code above\n","        ##################\n","        pass\n","\n","      return dist\n","\n","    ## Given a DataFrame row as a vector, returns indexes of k nearest neighbors\n","    def get_knn(self, row):\n","      distances = list()\n","      x = self.x\n","      k = self.k\n","      \n","      ##################\n","      ## Your code below - populate the distances list\n","      # hint: you can use a for loop\n","      for characteristicsVector in x:\n","        # print(\"these should be only 6 numbers: \", characteristicsVector, \"and this should be 6 num as well: \", row)\n","        # print(self.get_distance(characteristicsVector,row))\n","        distances.append(self.get_distance(characteristicsVector,row))\n","\n","      ## Your code above\n","      ##################\n","\n","      # Sort distances, and return the indexes of k first elements\n","      ans_indexes = np.argsort(distances)[:k]\n","      return ans_indexes\n","\n","    ## Given a DataFrame row as a vector, classify it according to KNN\n","    # hint: we have a list of k labels and want to return the most common one\n","    def classify(self, row):\n","      y = self.y\n","      nn_labels = [y[i] for i in self.get_knn(row)]\n","      \n","      ##################\n","      ## Your code below\n","      # print(\"nn_labels: \", nn_labels)\n","      mydict={}\n","      for asnwer in nn_labels:\n","        if asnwer not in mydict:\n","          mydict[asnwer]=1\n","        else:\n","          mydict[asnwer]+=1\n","      prediction=max(mydict, key=mydict.get)\n","      # print(\"mydict: \", mydict)\n","      for genres in mydict.keys():\n","        if(mydict[prediction]< mydict[genres] ):\n","          prediction = genres  \n","        elif (mydict[prediction] == mydict[genres] and prediction>genres):\n","          prediction= genres\n","         \n","      # print(\"old answer: \", mode(nn_labels))  \n","      # prediction = mode(nn_labels)\n","      # print(\"prediction: \", prediction)\n","      ## Your code above\n","      ###################\n","      return prediction\n","\n","\n","knn = KNN(x_train, y_train, k=3, distance='euclidian')"]},{"cell_type":"markdown","metadata":{"id":"B8-o5tn3aH0-"},"source":["Τώρα που είναι έτοιμος ο ταξινομητής ας δούμε τι προβλέπει σε μεμονωμένα δείγματα."]},{"cell_type":"markdown","metadata":{"id":"XCiEi1UUaLzE"},"source":["## Αξιολόγηση του KNN"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"tKw0oa1jaJei"},"outputs":[],"source":["knn = KNN(x_train, y_train, k=5, distance='euclidian')\n","preds = [knn.classify(x_test2[i]) for i in range(100) ]\n","# print(preds)\n","labels = [y_test2[i] for i in range(100)]"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"yNVygiKCaNag"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.8101608536391146\n","recall: 0.815634498480243\n","f1: 0.8046557147145101\n","accuracy: 0.8100000000000005\n","Confusion matrix: \n","[[18  3  0]\n"," [ 8 38  1]\n"," [ 2  5 25]]\n"]}],"source":["eval = Evaluate(labels, preds)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"V7LP247HaU6m"},"source":["## Έτοιμος ΚΝΝ classifier\n","\n","Όπως και με τους περισσότερους αλγορίθμους μηχανικής μάθησης, υπάρχουν έτοιμες βελτιστοποιημένες υλοποιήσεις. Παρακάτω δείχνουμε ένα παράδειγμα χρήσης του ταξινομητή ΚΝΝ που παρέχει η βιβλιοθήκη sklearn ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html))."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Os0WCL-QaOnr"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.8101608536391146\n","recall: 0.815634498480243\n","f1: 0.8046557147145101\n","accuracy: 0.8100000000000005\n","Confusion matrix: \n","[[18  3  0]\n"," [ 8 38  1]\n"," [ 2  5 25]]\n"]}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","k = 5\n","knc = KNeighborsClassifier(n_neighbors = k)\n","knc.fit(x_train, y_train)\n","y_pred = knc.predict([(x_test2[i]) for i in range(100)])\n","\n","\n","eval = Evaluate(y_test2[:100], y_pred)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"RcUBX2XMaZUd"},"source":["## Σύγκριση υλοποιήσεων\n","\n","Στα παρακάτω κελιά πειραματιστείτε με τις δύο υλοποιήσεις (τη δική σας και την έτοιμη). Βεβαιωθείτε πως προκύπτουν τα ίδια αποτελέσματα για διάφορες τιμές του k (για ευκλείδια απόσταση) και μετρήστε τους χρόνους εκτέλεσης."]},{"cell_type":"markdown","metadata":{"id":"IOmj0ryqW9nY"},"source":["Για τους χρόνους εκτέλεσης για k = 5 τρέχουμε τα 3 παρακάτω κελιά:"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"8Yz_Y_cpaWor"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 5.28 s\n"]}],"source":["%%time\n","knn = KNN(x_train, y_train, k = 5, distance='euclidian')\n","preds_eu = [knn.classify(x_test[i]) for i in range(100)]\n"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"683epgE6W9nY"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7103503097417905\n","recall: 0.697018162103551\n","f1: 0.700446912242687\n","accuracy: 0.7000000000000004\n","Confusion matrix: \n","[[19 10  2]\n"," [ 8 25  1]\n"," [ 7  2 26]]\n","Wall time: 10.8 s\n"]}],"source":["%%time\n","knn = KNN(x_train, y_train, k = 5, distance = 'cosine')\n","preds_co = [knn.classify(x_test2[i]) for i in range(100)]\n","eval = Evaluate(preds_co, y_test2)\n","eval.get_evaluation_report()"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"77s6o3ZkabCY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 17 ms\n"]}],"source":["%%time\n","knc = KNeighborsClassifier(n_neighbors = 5)\n","knc.fit(x_train, y_train)\n","y_pred = knc.predict(x_test[:100])\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["every KNN has the same prediction \n"]}],"source":["def isTheSame(k, preds, y_preds, mylist, resultsForKNeighborsClassifier, resultsForKNN):\n","    counter=0\n","    check=0\n","    for a,b in zip(preds,y_preds):\n","        if(a != b):\n","            print(\"found not equality in \", counter, \" element of pred with k= \", k, \" preds= \",a, \" y_preds= \",b, \"this should be \", y_test[counter])\n","            print(\"x= \", x_test[counter])\n","            check+=1\n","        counter+=1\n","    if(check==0):\n","        mylist.append(True)\n","    else:\n","        mylist.append(False)\n","    resultsForKNN.append(Evaluate(preds, y_test2).get_metrics())\n","    resultsForKNeighborsClassifier.append(Evaluate(y_preds, y_test2).get_metrics())\n","\n","\n","diferent_values_k=[1, 2, 3, 5, 10, 20, 30]\n","mylist=[]\n","resultsForKNeighborsClassifier, resultsForKNN = [], []\n","for valueOfK in diferent_values_k:\n","    knn = KNN(x_train, y_train, k = valueOfK, distance='euclidian')\n","    preds_eucl = [knn.classify(x_test2[i]) for i in range(100)]\n","\n","    knc = KNeighborsClassifier(n_neighbors = valueOfK)\n","    knc.fit(x_train, y_train)\n","    y_pred = knc.predict(x_test2[:100])\n","    isTheSame(valueOfK, preds_eucl, y_pred, mylist, resultsForKNeighborsClassifier, resultsForKNN)\n","    \n","answers = 0\n","for i in mylist:\n","    if(i == True):\n","        answers+=1\n","if(answers == len(diferent_values_k) ):\n","    print(\"every KNN has the same prediction \")\n","\n","\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[k= 1 ] \n","KKN:  {'precision': 0.7259055217831815, 'recall': 0.7266899766899767, 'f1': 0.7168565038747593, 'accuracy': 0.7300000000000004}\n","KNeighborsClassifier:  {'precision': 0.7259055217831815, 'recall': 0.7266899766899767, 'f1': 0.7168565038747593, 'accuracy': 0.7300000000000004}\n","[k= 2 ] \n","KKN:  {'precision': 0.6893047112462005, 'recall': 0.7108713779445486, 'f1': 0.6619443322369053, 'accuracy': 0.6600000000000004}\n","KNeighborsClassifier:  {'precision': 0.6893047112462005, 'recall': 0.7108713779445486, 'f1': 0.6619443322369053, 'accuracy': 0.6600000000000004}\n","[k= 3 ] \n","KKN:  {'precision': 0.7822526173590004, 'recall': 0.7830987292277615, 'f1': 0.769712743396954, 'accuracy': 0.7800000000000005}\n","KNeighborsClassifier:  {'precision': 0.7822526173590004, 'recall': 0.7830987292277615, 'f1': 0.769712743396954, 'accuracy': 0.7800000000000005}\n","[k= 5 ] \n","KKN:  {'precision': 0.815634498480243, 'recall': 0.8101608536391146, 'f1': 0.8046557147145101, 'accuracy': 0.8100000000000005}\n","KNeighborsClassifier:  {'precision': 0.815634498480243, 'recall': 0.8101608536391146, 'f1': 0.8046557147145101, 'accuracy': 0.8100000000000005}\n","[k= 10 ] \n","KKN:  {'precision': 0.8397922998986829, 'recall': 0.8169482846902202, 'f1': 0.8234498543487309, 'accuracy': 0.8300000000000005}\n","KNeighborsClassifier:  {'precision': 0.8397922998986829, 'recall': 0.8169482846902202, 'f1': 0.8234498543487309, 'accuracy': 0.8300000000000005}\n","[k= 20 ] \n","KKN:  {'precision': 0.8276870145221209, 'recall': 0.8124437927663735, 'f1': 0.8178053830227744, 'accuracy': 0.8300000000000005}\n","KNeighborsClassifier:  {'precision': 0.8276870145221209, 'recall': 0.8124437927663735, 'f1': 0.8178053830227744, 'accuracy': 0.8300000000000005}\n","[k= 30 ] \n","KKN:  {'precision': 0.8189061972306653, 'recall': 0.8164347663318151, 'f1': 0.817464244480573, 'accuracy': 0.8300000000000005}\n","KNeighborsClassifier:  {'precision': 0.8189061972306653, 'recall': 0.8164347663318151, 'f1': 0.817464244480573, 'accuracy': 0.8300000000000005}\n"]}],"source":["counter=0\n","for r1, r2 in zip(resultsForKNeighborsClassifier, resultsForKNN) :\n","    print(\"[k=\", diferent_values_k[counter], \"] \")\n","    print(\"KKN: \",r1)\n","    print(\"KNeighborsClassifier: \", r2)\n","    counter+=1"]},{"cell_type":"markdown","metadata":{"id":"A6rb5SKKW9nY"},"source":["Για τους χρόνους εκτέλεσης για k = 50 τρέχουμε τα 3 παρακάτω κελιά:"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"YvDbD3u7W9nZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 5.35 s\n"]}],"source":["%%time\n","knn = KNN(x_train, y_train, k = 50, distance='euclidian')\n","preds = [knn.classify(x_test[i]) for i in range(100)]"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"4YpuwMD0W9nZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 574 ms\n"]}],"source":["%%time\n","knn = KNN(x_train, y_train, k = 50, distance = 'cosine')\n","preds = [knn.classify(x_test[i]) for i in range(5)]"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"3h4GOLcNW9nZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 20 ms\n"]}],"source":["%%time\n","knc = KNeighborsClassifier(n_neighbors = 50)\n","knc.fit(x_train, y_train)\n","y_pred = knc.predict(x_test[:100])"]},{"cell_type":"markdown","metadata":{"id":"bc9ySKoRaek-"},"source":["## Σχολιασμός\n","* Καθώς υλοποιήσαμε τον δικό μας ταξινομητή και συγκρίναμε τα αποτελέσματα με τον έτοιμο, παρατηρήσαμε ότι βγάζαμε σε κάποια δεδομένα διαφορετικό αποτέλεσμα. Καταλάβαμε ότι η διαφορά οφείλεται σε ισοβαθμία της πλειοψηφίας των k-γειτόνων. Για παράδειγμα, αν για k=5 τα είδη των 5 κοντινότερων γειτόνων είναι [0 0 1 2 2] τότε σύμφωνα με τον αλγόριθμο σωστές προβλέψεις είναι και το 0 και το 2. Για να υπάρχει συμφωνία με τον έτοιμο ταξινομητή επιλέξαμε να ταξινομεί το τραγούδι στο genre με την μικρότερη τιμή, στο παράδειγμα δηλαδή επιλέγουμε το genre 0.\n","* Όσον αφορά τον χρόνο εκτέλεσης, η έτοιμη υλοποίηση του αλγορίθμου είναι σαφώς πιο γρήγορη, καθώς χρειάζεται περίπου 20ms ενώ η δική μας χρειάζεται 5s περίπου (δηλάδη είναι πιο γρήγορη κατα 200 φορές περίπου).\n","* Η παράμετρος Κ επιδρά και στην επίδοση του ταξινομητή και στον χρόνο εκτέλεσης. Αυξάνοντας το Κ παρατηρούμε ότι η επίδοσή του είναι καλύτερη όμως η χρονική πολυπλοκότητα αυξάνεται σημαντικά.\n","* Αν συγκρίνουμε την δικιά μας υλοποιήση με την έτοιμη, βλέπουμε ότι οι μετρικές αξιολόγησης ( 'precision', 'recall', 'f1', 'accuracy') έχουν τις ίδιες τιμές, πράγμα που περιμέναμε αφού υλοποιείται ο ίδιος αλγόριθμος. \n"]},{"cell_type":"markdown","metadata":{"id":"Xe17UwwLag5Y"},"source":["# 3ο Μέρος: Naive Bayes\n","Στο τρίτο μέρος της άσκησης θα υλοποιήσετε τον αλγόριθμο Naive Bayes. Ας θυμηθούμε από τις διαφάνειες:\n","\n","**Υποθέσεις:**\n","- Τα χαρακτηριστικά είναι boolean αντί για συνεχή, δηλαδή παίρνουν δύο τιμές 0 ή 1. Συνεπώς, χρειάζεται να τροποποιήσουμε τα χαρακτηριστικά του dataset μας.\n","  - Για το συγκεκριμένο πρόβλημα μπορούμε να 'σπάσουμε' τις τιμές κάθε χαρακτηριστικού σε N διαφορετικά bins. Για παράδειγμα, για ένα χαρακτηριστικό που οι τιμές του κυμαίνονται στο [0, 1], για Ν=5, θα έχουμε τα ακόλουθα bins: [0, 0.2), [0.2, 0.4), [0.4, 0.6), [0.6, 0.8), [0.8, 1]. (Γι αυτό το λόγο στα προηγούμενα βήματα αναφέραμε ότι είναι σημαντικό να έχουμε τα χαρακτηριστικά μας στο [0, 1]!)\n","  \n","- Η πιθανότητα ένα στοιχείο με χαρακτηριστικά x να ανήκει στην κλάση i δίνεται από τον τύπο:\n","$$p(i|x)=\\frac{p(i)\\cdot{\\prod_{k=1}^p}p(x^{(k)}|i)}{\\sum_{j=1}^pp(x^{(k)}|j)}$$\n","- Για να ταξινομήσουμε ένα διάνυσμα χαρακτηριστικών x σε μια κλάση i επιλέγουμε την κλάση που μεγιστοποιεί την παραπάνω πιθανότητα\n","  - Μπορούμε για τη σύγκριση να αγνοήσουμε τον παρονομαστή, αφού για όλες τις κλάσεις θα είναι ίδιος"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"GNbBhsg2ach8"},"outputs":[],"source":["# κάνουμε κάθε μεταβλήτη του συνόλου εκπαίδευσης διακρίτη σε σε διαστήματα \n","\n","def discretize(x, num_of_classes = 5):  \n","    x_r = []\n","    for row in x:\n","        discrete = []\n","        for i, feature in enumerate(row):\n","            discrete_feature = [0] * num_of_classes\n","            for j, v in enumerate(np.linspace(0, 1, num_of_classes + 1)):\n","                if float(feature) < v:\n","                    break\n","            discrete_feature[j-1] = 1\n","            discrete += discrete_feature\n","        x_r.append(discrete)\n","    return np.array(x_r)\n","\n","x_train_r = discretize(x_train)\n","\n","x_test_r = discretize(x_test)"]},{"cell_type":"markdown","metadata":{"id":"lFORd6XJakZl"},"source":["Παρακάτω σας δίνεται η κλάση NaiveBayes που υλοποιεί τον αλγόριθμο. Καλείστε αρχικά να υπολογίσετε την πιθανότητα $p(x^{(k)}|i)$ για διάνυσμα χαρακτηριστκών $x$ και κατηγορία $i$ στη μέθοδο compute_probabilities. Στη συνέχεια θα υπολογίσετε την πιθανότητα $p(i|x)$ στη μέθοδο predict."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"ufKo5f5yaiqH"},"outputs":[],"source":["class NaiveBayes:\n","    def __init__(self, x, y):\n","        self.x = x\n","        self.y = y\n","        ## pC is a vector with the probability of each class\n","        self.pC = np.zeros((len(genres),))\n","        ## pxC is an array with all probabilities p(xi|C)\n","        self.pxC = np.zeros((x.shape[-1], len(genres)))\n","        ## Compute the probabilities\n","        self.compute_probabilities()\n","\n","    def compute_probabilities(self):\n","        ## Compute p(C) for each class\n","        for label in self.y: self.pC[label] += 1\n","        self.pC = self.pC / self.y.shape[0]\n","\n","        ## Compute p(xi|C) for each feature xi and class C\n","        # hint: you can use one or more for loops\n","        ###################\n","        ## Your code below\n","        \n","        num_genre = np.zeros((3,))\n","        \n","        for i in range(len(self.y)):\n","            genre = self.y[i]\n","            num_genre[genre]+=1\n","            for c in range(0,30):\n","                if (self.x[i][c] == 1): \n","                    self.pxC[c][genre]+=1\n","                    \n","        \n","        \n","        for i in range(3):\n","            for j in range(self.x.shape[-1]):\n","                self.pxC[j][i] = self.pxC[j][i]/num_genre[i]\n","        \n","        ## Your code above\n","        ##################\n","\n","    def predict(self, x):\n","        ## ~Probability of x belonging to each class\n","        ## (not actucal probability since we ignore denominator)\n","        pcX = np.ones((len(genres),))\n","        xsize = self.x.shape[-1]\n","        for i in range(len(genres)):\n","          # hint: We have probabilities p({x_j=1}|i) in self.pxC\n","          # We also need p({x_j=0}|i) for computing p(x|i)\n","          #################\n","          ## Your code below\n","            product = 1\n","            for characteristic in range(xsize):\n","                if (x[characteristic] == 1):\n","                    product = product*self.pxC[characteristic][i] \n","                else:\n","                    product = product*(1-self.pxC[characteristic][i])\n","            pcX[i] = product * self.pC[i]\n","\n","\n","\n","\n","          ## Your code above\n","          ##################\n","        return np.argmax(pcX)"]},{"cell_type":"markdown","metadata":{"id":"cO9h_Q8bbAgF"},"source":["## Αξιολόγηση του Naive Bayes"]},{"cell_type":"markdown","metadata":{},"source":["### Τυχαιοποίηση για τα διακριτά δεδομένα.\n","Με όμοιο τρόπο, δημιουργούμε και σε αυτό το μέρος σύνολο με τυχαία δείγματα."]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["y_test2,x_test_r2, x_test2 =[],[],[]\n","\n","alreadyVisited={}\n","number_of_songs = 100\n","while(number_of_songs>0):\n","    randomNumber= random.randrange(0,(len(x_test_r)))\n","    newlist=[]\n","    newlist=list(x_test_r[randomNumber])\n","    newlist.append(randomNumber)\n","    if(str(newlist) in alreadyVisited):\n","        continue\n","    else:\n","        number_of_songs-=1\n","        x_test2.append(x_test[randomNumber])\n","        x_test_r2.append(x_test_r[randomNumber])\n","        y_test2.append(y_test[randomNumber])"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"2PzuaP48amDv"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7353640511535248\n","recall: 0.7087604846225536\n","f1: 0.6948100386496403\n","accuracy: 0.7000000000000004\n","Confusion matrix: \n","[[17  9  8]\n"," [ 2 27  8]\n"," [ 0  3 26]]\n"]}],"source":["nb = NaiveBayes(x_train_r, np.array(y_train))\n","preds = [nb.predict(i) for i in x_test_r2[:100]]\n","eval = Evaluate(y_test2[:100], preds)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"xMUHg-dubFa2"},"source":["## Έτοιμος Naive Bayes\n","\n","Όπως με τους περισσότερους αλγορίθμους μηχανικής μάθησης, υπάρχουν έτοιμες βελτιστοποιημένες υλοποιήσεις για τον Naive Bayes. Παρακάτω ο Gaussian Naive Bayes από το Sklearn. Σε αντίθεση με τη δική μας υλοποίηση, ο συγκεκριμένος δουλεύει και με συνεχή δεδομένα, αφού πρώτα κάνει την υπόθεση πως κάθε χαρακτηριστικό ακολουθεί κανονική κατανομή ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html))."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"qNir3SOIW9nb"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7149393090569561\n","recall: 0.7022367194780988\n","f1: 0.684045633341408\n","accuracy: 0.6900000000000004\n","Confusion matrix: \n","[[17  7 10]\n"," [ 4 25  8]\n"," [ 0  2 27]]\n"]}],"source":["from sklearn.naive_bayes import GaussianNB\n","\n","gnb = GaussianNB()\n","y_pred = gnb.fit(x_train, y_train).predict(x_test2[:100])\n","\n","eval = Evaluate(y_test2[:100], y_pred)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"KaecLreybI-3"},"source":["## Σύγκριση υλοποιήσεων\n","\n","Όμοια με πριν θα συγκρίνετε τα αποτελέσματα και τους χρόνους εκτέλεσης για τις δύο υλοποιήσεις. Σχολιάστε την επίδοση σε κάθε περίπτωση. Ποιες από τις παραδοχές που κάναμε δεν ισχύουν;"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"Lz-k1DL-bG9v"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7087604846225536\n","recall: 0.7353640511535248\n","f1: 0.6948100386496403\n","accuracy: 0.7000000000000004\n","Confusion matrix: \n","[[17  2  0]\n"," [ 9 27  3]\n"," [ 8  8 26]]\n","Wall time: 142 ms\n"]}],"source":["%%time\n","nb = NaiveBayes(x_train_r,np.array(y_train))\n","preds = [ nb.predict(i) for i in x_test_r2[:100]]\n","eval = Evaluate(preds, y_test2)\n","eval.get_evaluation_report()"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"neUU0A-AW9nc"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7022367194780988\n","recall: 0.7149393090569561\n","f1: 0.684045633341408\n","accuracy: 0.6900000000000004\n","Confusion matrix: \n","[[17  4  0]\n"," [ 7 25  2]\n"," [10  8 27]]\n","Wall time: 11.5 ms\n"]}],"source":["%%time\n","gnb = GaussianNB()\n","y_pred = gnb.fit(x_train, y_train).predict(x_test2[:100])\n","eval = Evaluate(y_pred, y_test2)\n","eval.get_evaluation_report()"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["found not equality in  2  element with preds=  2  y_preds=  1\n","found not equality in  8  element with preds=  1  y_preds=  2\n","found not equality in  14  element with preds=  0  y_preds=  1\n","found not equality in  16  element with preds=  2  y_preds=  1\n","found not equality in  21  element with preds=  0  y_preds=  1\n","found not equality in  22  element with preds=  0  y_preds=  1\n","found not equality in  23  element with preds=  1  y_preds=  2\n","found not equality in  35  element with preds=  2  y_preds=  1\n","found not equality in  39  element with preds=  0  y_preds=  2\n","found not equality in  44  element with preds=  0  y_preds=  2\n","found not equality in  51  element with preds=  0  y_preds=  1\n","found not equality in  55  element with preds=  0  y_preds=  1\n","found not equality in  57  element with preds=  0  y_preds=  2\n","found not equality in  71  element with preds=  1  y_preds=  2\n","found not equality in  81  element with preds=  0  y_preds=  1\n","found not equality in  85  element with preds=  1  y_preds=  2\n"]}],"source":["def isTheSame(preds, y_preds):\n","    counter=0\n","    for a,b in zip(preds,y_preds):\n","        if(a != b):\n","            print(\"found not equality in \", counter, \" element with preds= \",a, \" y_preds= \",b)\n","        counter+=1\n","\n","nb = NaiveBayes(x_train_r,np.array(y_train))\n","preds = [ nb.predict(i) for i in x_test_r[:100]]\n","gnb = GaussianNB()\n","y_pred = gnb.fit(x_train, y_train).predict(x_test[:100])\n","isTheSame(preds,y_pred)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SAmP4BrCbOB9"},"source":["### Σχολιασμός\n","\n","* Αρχικά, παρατηρούμε ότι για κάθε 5-άδα που αφορά το κάθε χαρακτηριστικό μόνο ή μία τιμή μπορεί να είναι μονάδα - οι υπόλοιπες είναι αναγκαστικά 0.\n","Το σε ποιες θέσεις θα υπάρχουν αυτες οι μονάδες, για κάθε χαρακτηριστικό, αποτελούν 6 ανεξάρτητα ενδεχόμενα τα οποία χρησιμοποιούμε στο γινόμενο του αριθμητή του δοσμένου τύπου.\n","* Ο έτοιμος ταξινομητής χρησιμοποιεί και συνεχή δεδομένα, θεωρώντας ότι ακολουθούν κανονική κατανομή ενώ η δική μας υλοποίηση χρησιμοποιεί μόνο δεδομένα boolean. Αυτός είναι και ο λόγος που βρίσκουμε αρκετές διαφορές στην ταξινόμηση των τραγουδιών.\n","* Όσον αφορά την σύγκριση των δύο ταξινομητών, ως προς την επίδοση η έτοιμη έχει λίγο χαμηλότερο accurancy. Παρατηρήσαμε, όμως, ότι για διαφορετικά σύνολα δεδομένων η τιμή αυτή αλλάζει αλλά η διαφορά της επίδοσης αυτών των δύο είναι πολύ μικρή, Ως προς την ταχύτητα, η έτοιμη είναι πιο γρήγορη κατά περίπου 10 φορές."]},{"cell_type":"markdown","metadata":{"id":"8B3FYDfnW9nd"},"source":["# 4ο Μέρος: Multi-Layer Perceptron \n","\n","Στο τέταρτο μέρος της άσκησης θα κατασκευάσετε ένα πολυεπίπεδο νευρωνικό δίκτυο. Ο ταξινομητής αυτός θα εκπαιδευτεί στο να ταξινομεί τα δείγματα των μουσικών κομματιών σε μια από τις 3 διαφορετικές κλάσεις που επιλέχθηκαν (Electronic, Rock, Rap). Αρχικά, θα υλοποιήσετε το μοντέλο αυτό χρησιμοποιώντας αποκλειστικά την βιβλιοθήκη numpy ενώ στην συνέχεια θα χρησιμοποιήσετε μια έτοιμη κλάση για την κατασκευή του ίδιου μοντέλου. \n","\n","Ας θυμηθούμε από τις διαφάνειες: \n","\n","Κάθε MLP αποτελείται από επίπεδα όπου το κάθε ένα από αυτά χωρίζεται στα παρακάτω μέρη: \n","\n","$$ z(x) = w^Τx + b $$ \n","$$ f(x) = a(z(x))$$ \n","\n","όπου $w$, $b$ είναι τα βάρη του επιπέδου.  Η έξοδος z(x) είναι η απόκριση κάθε νευρώνα πριν την συνάρτηση ενεργοποίησης ενώ η f(x) μετά.  Κάθε επίπεδο συνδέεται με ένα επόμενο του οποίου η είσοδός του αποτελεί την έξοδο (με την συνάρτηση ενεργοποίησης) του προηγούμενου. \n","\n","Στο μέρος αυτό καλείστε να συμπληρώσετε ορισμένα σημεία κώδικα ώστε να επιτυγχάνεται αυτή η λειτουργικότητα. Στην συνέχεια θα υλοποιήσετε το ίδιο ακριβώς μοντέλο χρησιμοποιώντας όμως μια έτοιμη βιβλιοθήκη και θα συγκρίνετε τα αποτελέσματά τους (χρόνο, σκορ κ.α.). \n","\n","Σε αυτό το σημείο της άσκησης θα επιλύσετε το παραπάνω πρόβλημα κατασκευάζοντας ένα πολυεπίπεδο νευρωνικό δίκτυο. Αρχικά θα υλοποιήσετε το νευρωνικό χωρίς να χρησιμοποιήσετε κάποια έτοιμη κλάση κάποιας βιβλιοθήκης (όπως scikit-learn, keras), ενώ στην συνέχεια θα κατασκευάσετε το ίδιο σύστημα με την χρήση της βιβλιοθήκης scikit-learn. \n","\n","Στο παρακάτω κελί κώδικα σάς δίνεται η βασική δομή του επιπέδου ενός πολυεπίπεδου νευρωνικού δικτύου. Η παρακάτω κλάση δεν υλοποιεί κάποιο πραγματικό επίπεδο (όπως Dense) αλλά αυτή χρησιμοποιείται για την παρουσίαση των λειτουργιών κάθε επιπέδου.\n","\n","Ουσιαστικά κάθε επίπεδο ενός νευρωνικού δικτύου πρέπει να είναι σε θέση να κάνει: \n","\n","\n","1.   Για μια είσοδο να υπολογίζει την έξοδο κάθε νευρώνα. Αυτό επιτυγχάνεται μέσω της μεθόδου forward η όποια δέχεται ως όρισμα μια είσοδο  και επιστρέφει έναν πίνακα με τις εξόδους κάθε νευρώνα του επιπέδου. \n","\n","2.   Να υπολογίζει τις μεταβολές οι όποιες πρέπει να γίνουν στα βάρη κάθε επιπέδου, ανάλογα με το πόσο καλά-κοντινά ήταν τα αποτελέσματα του επιπέδου στα πραγματικά. Η λειτουργία αυτή θα μας βοηθήσει στην ανανέωση των βαρών του δικτύου και συνεπώς στη σωστή εκπαίδευσή του. Η λειτουργικότητα αυτή επιτυγχάνεται μέσω της μεθόδου backward. \n","\n","  \n","\n","Η λειτουργικότητα, συνεπώς, κάθε επιπέδου καθορίζεται από την συνάρτηση που υλοποιείται στην μέθοδο forward. Ένα instance της παρακάτω κλάσης, συνεπώς, επιστρέφει ως έξοδο την είσοδο κάθε νευρώνα (ταυτοτική συνάρτηση) όποτε δεν προσφέρει κάποια υψηλή λειτουργικότητα. Στην παρακάτω κλάση δεν έχετε να προσθέσετε κάτι, απλά να μελετήσετε και να καταλάβετε την δομή που πρέπει να έχει ένα επίπεδο. "]},{"cell_type":"code","execution_count":66,"metadata":{"id":"jgx1VIMmbMQP"},"outputs":[],"source":["class Layer:\n","    def __init__(self):\n","        \"\"\"Here we can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n","        # A dummy layer does nothing\n","        pass\n","    \n","    def forward(self, input):\n","        \"\"\"\n","        Takes input data of shape [batch, input_units], returns output data [batch, output_units]\n","        \"\"\"\n","        # A dummy layer just returns whatever it gets as input.\n","        return input\n","\n","    def backward(self, input, grad_output):\n","        # The gradient of a dummy layer is precisely grad_output, but we'll write it more explicitly\n","        num_units = input.shape[1]\n","        \n","        d_layer_d_input = np.eye(num_units)\n","        \n","        return np.dot(grad_output, d_layer_d_input) # chain rule"]},{"cell_type":"markdown","metadata":{"id":"r1iQCroAbV-F"},"source":["Στο σημείο αυτό αξίζει να αναφερθεί ότι για την σωστή εκπαίδευση του δικτύου (σε πρακτικό επίπεδο) πρέπει να διαχωριστεί η έξοδος κάθε νευρώνα πριν και μετά την συνάρτηση ενεργοποίησης. Έτσι η παραπάνω μέθοδος forward της κλάσης layer πρέπει να υπολογίζει την έξοδο του επιπέδου χωρίς την συνάρτηση ενεργοποίησης και κάποια άλλη κλάση να υπολογίζει το αποτέλεσμα με αυτή.  \n","\n","  \n","\n","Έκτος όμως από την εκπαίδευση του δικτύου, ο διαχωρισμός αυτός μας βοηθά σημαντικά και κατά την φάση σχεδιασμού της  αρχιτεκτονικής μιας και μας δίνει την δυνατότητα να αλλάζουμε την συνάρτηση ενεργοποίησης χωρίς κάθε φόρα να πρέπει να αλλάξουμε ολόκληρη την κλάση layer. Για τους παραπάνω λόγους θα χειριζόμαστε την συνάρτηση ενεργοποίησης σαν ένα ξεχωριστό επίπεδο με τις δικές της μεθόδους: forward, backward.  \n","\n","  \n","\n","Παρακάτω παρουσιάζεται η κλάση η όποια υλοποιεί την λειτουργικότητα της συνάρτησης ενεργοποίησης [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)).  \n","\n","  \n","\n","Με την ίδια λογική μπορούμε να υλοποιήσουμε οποιαδήποτε άλλη συνάρτηση ενεργοποίησης θέλουμε π.χ. sigmoid, tanh κ.ο.κ. και επιπλέον μπορούμε να τις εναλλάσσουμε μεταξύ επιπέδων χωρίς δυσκολία. "]},{"cell_type":"code","execution_count":67,"metadata":{"id":"6P33228VbYIf"},"outputs":[],"source":["class ReLU(Layer):\n","    def __init__(self):\n","        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n","        pass\n","    \n","    def forward(self, input):\n","        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n","        relu_forward = np.maximum(0, input)\n","        return relu_forward\n","    \n","    def backward(self, input, grad_output):\n","        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n","        relu_grad = input > 0\n","        return grad_output*relu_grad"]},{"cell_type":"markdown","metadata":{"id":"Rrrub_76ba19"},"source":["Η κλάση Dense υλοποιεί ένα επίπεδο dense όπου η έξοδος κάθε νευρώνα (χωρίς τη  συνάρτηση ενεργοποίησης) υπολογίζεται από την παρακάτω εξίσωση: \n","\n","  \n","\n","  \n","\n","$$ z(x) = w^Τx + b $$ \n","\n","  \n","\n","όπου $w$, $b$ είναι τα βάρη του επιπέδου.   \n","\n","  \n","\n","Συνεπώς το δίκτυο είναι απαραίτητο να διατηρεί τους δυο πίνακες με τα βάρη οι οποίοι στην μέθοδο forward θα χρησιμοποιούνται για τον υπολογισμό της εξόδου και θα ανανεώνονται από την μέθοδο backward. Οι πίνακες αυτοί δημιουργούνται κατά την κατασκευή κάθε στιγμιότυπου και αρχικοποιούνται, ο πρώτος τυχαία και ο δεύτερος με μηδενικά.  Στο σημείο αυτό καλείστε να συμπληρώσετε την μέθοδο forward με κατάλληλο τρόπο ώστε να επιτυγχάνεται η επιθυμητή λειτουργικότητα. "]},{"cell_type":"code","execution_count":68,"metadata":{"id":"HEnuIuOHbZge"},"outputs":[],"source":["class Dense(Layer):\n","    def __init__(self, input_units, output_units, learning_rate = 0.1):\n","        self.input_units = input_units\n","        self.output_units = output_units\n","        \n","        self.learning_rate = learning_rate\n","        self.weights = np.random.normal(loc = 0.0, \n","                                        scale = np.sqrt(2 / (input_units + output_units)), \n","                                        size = (input_units, output_units))\n","        self.biases = np.zeros(output_units)\n","        \n","    def forward(self, input):\n","        \"\"\"\n","        Perform an affine transformation:\n","        f(x) = <W*x> + b\n","        \n","        input shape: [number of inputs, input units]\n","        output shape: [number of inputs, output units]\n","        \"\"\"\n","        ###################\n","        ## Your code below\n","        ## hint: numpy.dot\n","\n","        # print(\"W= \")\n","        # print(self.weights)\n","        # print(\"b= \")\n","        # print(self.biases)\n","        # print(\"X= \")\n","        # print(self.input_units)\n","        output = np.dot(input,self.weights)+self.biases\n","        \n","        ## Your code above\n","        ##################\n","        return output\n","\n","    def backward(self, input, grad_output):\n","        # compute d f / d x = d f / d dense * d dense / d x\n","        # where d dense/ d x = weights transposed\n","        grad_input = np.dot(grad_output, self.weights.T)\n","\n","        # compute gradient w.r.t. weights and biases\n","        grad_weights = np.dot(input.T, grad_output)\n","        grad_biases = grad_output.mean(axis = 0) * input.shape[0]\n","        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n","\n","        # Here we perform a stochastic gradient descent step. \n","        self.weights = self.weights - self.learning_rate * grad_weights\n","        self.biases = self.biases - self.learning_rate * grad_biases\n","        return grad_input"]},{"cell_type":"markdown","metadata":{"id":"Ml2jvLeybeRe"},"source":["Οι παρακάτω συναρτήσεις χρησιμοποιούνται για να μπορεί το δίκτυο να ελέγχει πόσο κοντά βρίσκονται τα αποτελέσματά του στα πραγματικά (Loss function). Όπως είναι λογικό υπάρχουν διαφορετικές τέτοιες συναρτήσεις ανάλογα το πρόβλημα που καλείται να λύσει το δίκτυο. Η παρακάτω συνάρτηση ονομάζεται [softmax](https://en.wikipedia.org/wiki/Softmax_function) και χρησιμοποιείται κατά κύριο λόγο σε προβλήματα ταξινόμησης όπως το συγκεκριμένο. Η softmax δέχεται σαν είσοδο τις ενεργοποιήσεις του τελευταίου επιπέδου και επιστρέφει μια κατανομή πιθανοτήτων για κάθε μια από τις κλάσεις εξόδου (π.χ. κλάση 0 έχει πιθανότητα 0.001,  η κλάση 1 έχει 0.9 κ.ο.κ.).  "]},{"cell_type":"code","execution_count":69,"metadata":{"id":"qT7nl_1Gbc0B"},"outputs":[],"source":["def softmax_crossentropy_with_logits(logits, reference_answers):\n","    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n","    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n","    return xentropy\n","\n","def grad_softmax_crossentropy_with_logits(logits, reference_answers):\n","    ones_for_answers = np.zeros_like(logits)\n","    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n","    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n","    return (- ones_for_answers + softmax) / logits.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"5XnSJjxYbhdX"},"source":["Έχοντας υλοποιήσει τις κλάσεις Dense και ReLU μπορούμε πλέον να κατασκευάσουμε μια κλάση η όποια θα ορίζει ένα πολυεπίπεδο νευρωνικό δίκτυο (MLP). Το δίκτυο αυτό ουσιαστικά αποτελείται από μια ακολουθία Dense επιπέδων όπου το κάθε ένα (εκτός του τελευταίου) ακολουθείται από μια μη-γραμμική συνάρτηση ενεργοποίησης (ReLU). Όμοια με πριν, η κλάση αυτή πρέπει να περιέχει μια μέθοδο forward η όποια θα δέχεται μια είσοδο (εδώ μια εικόνα flatten) και θα επιστρέφει μια έξοδο (εδώ μια κατανομή 3 πιθανοτήτων). Παράλληλα πρέπει να περιέχει και μια μέθοδο fit, η όποια θα εκπαιδεύει το δίκτυο δεδομένου ενός τέτοιου συνόλου (εδώ του x_train). Στο σημείο αυτό χρησιμοποιούνται οι μέθοδοι backward που έχουν οριστεί για κάθε ένα επίπεδο (δεν χρειάζεται να συμπληρώσετε κάτι).  Τέλος θα ήταν βοηθητικό να έχουμε και μια μέθοδο η όποια θα μετατρέπει την κατανομή εξόδου στην επιστρεφόμενη κλάση (predict) για κάποιο ή κάποια στιγμιότυπα του συνόλου δεδομένων.   \n","\n","Το δίκτυο όπως αναφέρθηκε και προηγουμένως αποτελείται από έναν αριθμό Dense επιπέδων κάθε ένα από τα όποια ακολουθείται από μια συνάρτηση ReLU. Η κατασκευή των επιπέδων γίνεται κατά την στιγμή δημιουργίας του δικτύου, όπου δίνεται ως είσοδος μια λίστα με το μέγεθος κάθε επιπέδου, μαζί με το μέγεθος εισόδου. Έτσι για παράδειγμα η παρακάτω γραμμή κώδικα:  \n","``` \n","net = MLP([100, 200, 100, 10], 784)  \n","```  \n","κατασκευάζει ένα MLP το όποιο αποτελείται από 4 επίπεδα με μέγεθος 100, 200, 100, 10. Ο αριθμός των επιπέδων καθώς και του μεγέθους καθενός από αυτά είναι ελεύθερος να οριστεί από τον χρήστη.   \n","Στον constructor της κλάσης ουσιαστικά ορίζεται μια λίστα η όποια περιέχει κάθε ένα από τα επίπεδα που πρέπει να οριστούν, π.χ. για το παραπάνω παράδειγμα η μεταβλητή net.network περιέχει τα εξής στιγμιότυπα των κλάσεων:  \n","\n","``` \n","[Dense(100), ReLU(), Dense(200), ReLU(), Dense(100), ReLU(), Dense(10)]  \n","```  \n","\n","Συνεπώς η λειτουργικότητα του δικτύου όπως και πριν πρέπει να οριστεί στην μέθοδο forward. Στο σημείο αυτό καλείστε να συμπληρώσετε την μέθοδο αυτή έτσι ώστε το δίκτυο να λειτουργεί όπως πρέπει, δηλαδή στο παράδειγμά μας η είσοδος να περνά από το επίπεδο Dense(100), μετά από το ReLU(), στην συνέχεια από το Dense(200) κ.ο.κ. μέχρι και το τελευταίο επίπεδο.  Ο αλγόριθμος αυτός παρουσιάζεται και σε ψευδοκώδικα στην διαφάνεια 33 του μαθήματος. "]},{"cell_type":"code","execution_count":71,"metadata":{"id":"MHHcg1unbf21"},"outputs":[],"source":["class MLP:\n","    def __init__(self, shapes, input_dim):\n","        self.shapes = shapes\n","        self.network = [Dense(input_dim, shapes[0])]\n","        self.network.append(ReLU())\n","        for i in range(1, len(self.shapes) - 1):\n","            self.network.append(Dense(shapes[i-1], shapes[i]))\n","            self.network.append(ReLU())\n","        self.network.append(Dense(shapes[i], shapes[-1]))\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Αγόριθμος διφάνειας 33\n","        \"\"\"\n","        activations = []\n","        input = X\n","        # Looping through each layer\n","        for l in self.network:\n","            ###################\n","            ## Your code below\n","            # hint: τροφοδοτούμε την έξοδο κάθε επιπέδου στο επόμενο\n","            \n","            input=l.forward(input)\n","            activations.append(input)\n","\n","\n","            ## Your code above\n","            ##################        \n","        assert len(activations) == len(self.network)\n","        return activations\n","\n","    def predict(self,X):\n","        \"\"\"\n","        Προβλέπει την έξοδο του δικτύου για ένα ή περισσότερα στιγμιότυπα εισόδου\n","        \"\"\"\n","        logits = self.forward(X)[-1]\n","        return logits.argmax(axis = -1)\n","\n","    def fit(self, X, y):\n","        # Get the layer activations\n","        layer_activations = self.forward(X)\n","        layer_inputs = [X]+layer_activations \n","        logits = layer_activations[-1]\n","\n","        # Compute the loss and the initial gradient\n","        loss = softmax_crossentropy_with_logits(logits,y)\n","        loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n","\n","        # Propagate gradients through the network\n","        # Reverse propogation as this is backprop\n","        for layer_index in range(len(self.network))[::-1]:\n","            layer = self.network[layer_index]\n","            loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) \n","        return np.mean(loss)"]},{"cell_type":"markdown","metadata":{"id":"6zCBcKqvbm4t"},"source":["## Αξιολόγηση ενός Multi-Layer Perceptron\n","\n","Αφού έχουμε κατασκευάσει τα παραπάνω είμαστε πλέον σε θέση να εκπαιδεύσουμε το MLP. Αυτό γίνεται καλώντας την μέθοδο fit. Στο παρακάτω κελί κώδικα ορίζεται το MLP του παραπάνω παραδείγματος και εκπαιδεύεται για 25 εποχές. Στο τέλος κάθε εποχής παρουσιάζονται τα αποτελέσματα του μαζί με μια γραφική των train και test accuracy. "]},{"cell_type":"code","execution_count":85,"metadata":{"id":"4jw-8qN6bjQG"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 24\n","Train accuracy: 0.47345086033991346\n","Val accuracy: 0.47215377033021194\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["precision: 0.5007393706112455\n","recall: 0.47393464617373215\n","f1: 0.3827975273086437\n","accuracy: 0.47215377033019845\n","Confusion matrix: \n","[[ 560   36  743]\n"," [ 103   13 1252]\n"," [   8    0 1343]]\n"]}],"source":["from IPython.display import clear_output\n","import numpy as np\n","\n","network = MLP([10, 15, 20, 3], len(inputs))\n","\n","train_log = []\n","val_log = []\n","\n","for epoch in range(25):\n","    network.fit(np.array(x_train), (y_train))   \n","    train_log.append(np.mean(network.predict(x_train) == y_train))\n","    val_log.append(np.mean(network.predict(x_test) == y_test))\n","    clear_output()\n","    print(\"Epoch\", epoch)\n","    print(\"Train accuracy:\", train_log[-1])\n","    print(\"Val accuracy:\", val_log[-1])  \n","    plt.plot(train_log,label = 'train accuracy')\n","    plt.plot(val_log,label = 'val accuracy')\n","    plt.legend(loc = 'best')\n","    plt.grid()\n","    plt.show()\n","\n","preds = network.predict(x_test)\n","\n","eval = Evaluate(y_test, preds)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"ygud3NX3b-wN"},"source":["## Έτοιμο Multi-Layer Perceptron \n","\n","Όπως και με τις τεχνικές των παραπάνω ερωτημάτων έτσι και εδώ υπάρχει έτοιμη η παραπάνω κλάση σε διάφορες βιβλιοθήκες. Έτσι στο δεύτερο μέρος του ερωτήματος αυτού θα κατασκευάσετε το ίδιο MLP χρησιμοποιώντας όμως την έτοιμη κλάση [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)  της βιβλιοθήκης scikit-learn. Παρακάτω παρουσιάζεται ένα παράδειγμα χρήσης της κλάσης αυτής. "]},{"cell_type":"code","execution_count":73,"metadata":{"id":"hltXBE2Vbojo"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.7259940723308107\n","recall: 0.7185632470659516\n","f1: 0.7160402833018166\n","accuracy: 0.7190734351897656\n","Confusion matrix: \n","[[ 788  273  278]\n"," [ 181 1024  163]\n"," [  39  206 1106]]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Nikolas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["from sklearn.neural_network import MLPClassifier\n","\n","epochs = 25\n","mlp = MLPClassifier(hidden_layer_sizes=(10, 15, 20), max_iter = epochs)\n","\n","mlp.fit(x_train,y_train)\n","\n","y_pred = mlp.predict(x_test)\n","eval = Evaluate(y_test, y_pred)\n","eval.get_evaluation_report()"]},{"cell_type":"markdown","metadata":{"id":"DOQYML9wcDBk"},"source":["## Σύγκριση υλοποιήσεων \n","\n","  \n","\n","Στα παρακάτω κελιά πειραματιστείτε με τις δύο υλοποιήσεις (τη δική σας και την έτοιμη). Συγκρίνετε τα αποτελέσματά σας τόσο ως προς τους χρόνους εκτέλεσης αλλά και ως προς τα αποτελέσματα. Η διαφορά των αποτελεσμάτων προκύπτει από το ότι στην έτοιμη κλάση έχουν γίνει αρκετές βελτιστοποιήσεις στην λειτουργία, στον τρόπο εκπαίδευσης κ.α. με αποτέλεσμα να προκύπτουν καλύτερα αποτέλεσματα. Παρόλα αυτά στην δική μας κλάση έχουμε καλύτερο έλεγχο και έχουμε την δυνατότητα να σχεδιάσουμε πιο σύνθετες αρχιτεκτονικές καθώς να αλλάξουμε τις τιμές παραμέτρων που στην έτοιμη κλάση μπορεί να μην μας δίνεται η δυνατότητα. \n"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.6301646474060267\n","recall: 0.6801587301587301\n","f1: 0.6074335988190054\n","accuracy: 0.6100000000000003\n","Confusion matrix: \n","[[17  3  0]\n"," [ 5 17  2]\n"," [12 17 27]]\n","Wall time: 845 ms\n"]}],"source":["%%time\n","\n","network = MLP([10, 15, 20, 3], len(inputs))\n","\n","train_log = []\n","val_log = []\n","\n","for epoch in range(25):\n","    network.fit(np.array(x_train), (y_train))   \n","    train_log.append(np.mean(network.predict(x_train) == y_train))\n","    val_log.append(np.mean(network.predict(x_test2[:100]) == y_test2[:100]))\n","    clear_output() \n","    \n","\n","preds = network.predict(x_test2[:100])\n","eval = Evaluate(preds, y_test2[:100])\n","eval.get_evaluation_report()"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["precision: 0.751256327321236\n","recall: 0.7473214285714285\n","f1: 0.7389745987221442\n","accuracy: 0.7400000000000004\n","Confusion matrix: \n","[[22  5  1]\n"," [ 6 25  1]\n"," [ 6  7 27]]\n","Wall time: 577 ms\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Nikolas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}],"source":["%%time\n","epochs = 25\n","mlp = MLPClassifier(hidden_layer_sizes=(10, 15, 20), max_iter = epochs)\n","\n","mlp.fit(x_train,y_train)\n","\n","y_pred = mlp.predict(x_test2[:100])\n","eval = Evaluate(y_pred, y_test2[:100])\n","eval.get_evaluation_report()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Σχολιασμός για ML Perceptron\n","* Η έτοιμη υλοποιήση είναι πιο γρήγορη όχι όμως με μεγάλη διαφορά (2 φορές ταχύτερη) \n","* Τα metrics είναι σαφώς καλύτερα, κάτι που ήταν αναμενόμενο λόγω των βελτιστοποιήσεων που έχουν πραγματοποιηθεί.\n","* Μπορούμε να βελτιώσουμε την υλοποίηση μας ώστε να πλησιάζει την έτοιμη, χωρίς αυτό να είναι απαραίτητα επιθυμητό καθώς πρέπει να μεταβάλουμε κάποιους από τους ακόλουθους παράγοντες: Το πλήθος των εποχών, το βήμα εκμάθησης, τα επίπεδα των preceptrons και τις αρχικές τιμές των βαρών. "]},{"cell_type":"markdown","metadata":{"id":"gfrx064gcCr8"},"source":["# Αξιολόγηση- Συμπεράσματα \n","\n","  \n","\n","Τέλος στο σημείο αυτό καλείστε να αξιολογήσετε τις διάφορες τεχνικές ταξινόμησης (KNN, Naive Bayes, MLP), τα αποτελέσματά τους, τους χρόνους εκτέλεσης, και να παραθέσετε παρατηρήσεις καθώς και οτιδήποτε σας φάνηκε ενδιαφέρον ή ιδιαίτερο. \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","### Λίστα με φθίνουσα accuracy για τις διαφορες τεχνικές ταξινόμησης.\n","\n","\n","1. KNN (ευκλείδεια)      | accuracy: 0.81 | time: 5.28 s\n","2. KNN (sklearn)         | accuracy: 0.81 | time: 17 ms\n","3. MLP (sklearn)         | accuracy: 0.74 | time: 577 ms\n","4. KNN (cosine)          | accuracy: 0.70 | time: 10.8 s\n","5. Naive Bayes (δικό μας)| accuracy: 0.70 | time: 142 ms\n","6. Naive Bayes (sklearn) | accuracy: 0.69 | time: 11.5 ms\n","7. MLP (δικιά μας)       | accuracy: 0.61 | time: 845 ms\n","\n","\n","* Όσον αφορά τον χρόνο εκτέλεσης βλέπουμε ότι οι ταξινομητές της βιβλιοθήκης sklearn είναι πολύ γρήγοροι και οι τρεις. Βέβαια, στον ΚΝΝ όσο μεγαλώνει το Κ μεγάλωνει και η χρονική πολυπλοκότητα, το οποίο δεν είναι σίγουρα επιθυμητό.\n","* όσον αφορά την επίδοση παρατηρούμε κάποιες σημαντικές διαφορές, οι οποίες όμως αλλάζουν κάθε φορά για διαφορετικό σύνολο δεδομένων. Ανάλογα τα δεδομένα (είδος και εύρος) που θα έχουμε θα υπάρχει ένας ταξινομητής με μεγαλύτερη ακρίβεια, όμως δεν υπάρχει ξεκάθαρο κριτήριο για να τον ξεχωρίσουμε εκ των προτέρων. \n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"student_version_ai_ex_3_MUSIC_2021.ipynb","provenance":[{"file_id":"1jMcmgh8zbZCqnsWi79MccGxGI0K6zqLP","timestamp":1639639410795}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
